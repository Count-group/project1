Okay, I need to optimize the code for the problem where we handle cumulonimbus clouds on a 10-degenerate graph. The previous code used a degeneracy order and maintained sum_in and sum_out. Let me think about how to make this more efficient.

First, the degeneracy ordering part. The original code uses a priority queue approach with buckets. But maybe there's a more efficient way to compute the order. Oh, wait, in C++, using a linked list for buckets might be better for O(1) access and removal. But the original code uses unordered_sets, which have O(1) average case but maybe there's a way to optimize this part. However, for a 10-degenerate graph, the maximum degree in the buckets is low, so maybe the current approach is sufficient. Alternatively, using a vector and tracking the current minimum degree could work. Let me check the existing code.

Wait, in compute_degeneracy_order, they use buckets of unordered_sets. For each node, when processing, they update the degrees of neighbors. But maybe using a different data structure could speed this up. However, given that the problem constraints are high (n up to 3e5, m up to 3e6), the degeneracy ordering needs to be efficient. But perhaps this part isn't the bottleneck since it's done once during preprocessing.

Next, the main part of the code is handling the queries. The original approach for query type 2 is to calculate sum_in[x] plus the sum of outgoing edges (sum_out). But sum_out is computed by iterating through outgoing[x] and summing a[u] each time. Since outgoing[x] has at most 10 elements (because the graph is 10-degenerate), this is O(1) per query. So that's manageable even for 2e6 queries.

But maybe we can precompute sum_out for each node and maintain it during updates. Wait, but sum_out depends on the a values of the outgoing neighbors. So when a neighbor's a changes, how would that affect sum_out for x? For example, if x has an outgoing edge to y, then a[y] is part of x's sum_out. So when y is updated (type 1), x's sum_out would change. But since outgoing edges are directed from higher to lower in the degeneracy order, the outgoing edges are from x to nodes with lower position in the order. However, if a node z has an outgoing edge to x (so x is in outgoing[z]), then if x is updated (type 1), that affects sum_in of z, which is already handled by the code. But sum_out for x is the sum of a[u] where u is in outgoing[x].

So, in the original code, during a type 2 query, sum_out is calculated on the fly by iterating through outgoing[x] and summing a[u]. Since the size of outgoing[x] is at most 10, this is O(1) per query. But maybe if we can precompute sum_out for each node and maintain it when a[u] changes, we can avoid the loop during queries. However, maintaining sum_out would require that whenever any a[u] is updated, all nodes that have u in their outgoing list need to update their sum_out. But since each a[u] can be in the outgoing list of multiple nodes, this could be O(k) per update, where k is the number of nodes that have u in their outgoing. Since each node has up to 10 outgoing edges, but the in-degree (as incoming outgoing edges from others) could be large. So for example, if a node u is in outgoing lists of many nodes, updating all their sum_out when u's a changes would be O(k) per update, which is not feasible. Therefore, it's better to compute sum_out on the fly for each query.

Thus, the original approach is correct. But perhaps there are optimizations in the data structures.

Looking at the code, the outgoing edges are stored as a vector of vectors. When a type 2 query comes, the code loops through outgoing[x] and sums a[u]. Since outgoing[x] is small (at most 10), this is acceptable.

But maybe in practice, using a plain array or a more cache-friendly structure could help. For example, using vector<int> outgoing[n] is okay, but perhaps using a contiguous memory layout for the outgoing lists could improve cache performance. However, in C++, vectors are already contiguous, so each outgoing list is contiguous. So that's probably fine.

Another possible optimization is in the initial construction of outgoing edges. The original code builds the adjacency list for each node and then, after computing the order, checks for each u and v in adj[u] whether pos[u] > pos[v]. If so, adds v to outgoing[u]. This is O(m) time, which is acceptable.

Another point: the sum_in is precomputed by initializing sum_in[v] as the sum of a[u] for all u in outgoing[u] that point to v. Wait, no: sum_in[v] is the sum of a[u] where u has v in their outgoing list. Because outgoing[u] contains all nodes that u points to (i.e., u's outgoing edges). So for each u, for each v in outgoing[u], sum_in[v] += a[u]. So sum_in[v] represents the sum of a's from all nodes that have an outgoing edge to v.

Thus, when a node x is updated (type 1), all v in outgoing[x] (the nodes that x points to) will have their sum_in[v] increased by v. That's correct. Because x's a[x] is part of sum_in of those v's.

In a query for x, sum_in[x] is the sum of all a's of nodes that point to x (i.e., nodes u where u is in the outgoing list of some nodes, but for x, sum_in[x] is the sum of a[u] where u has x in their outgoing list). Then sum_out is the sum of a's of nodes that x points to (outgoing[x]). So the total is sum_in[x] (sum of a's pointing to x) plus sum_out (sum of a's of x's outgoing edges). Wait, no: the sum_in[x] is the sum of a's from nodes u where u has x in their outgoing list. So for x's adjacent nodes, those with higher pos in the order (since outgoing lists are built by u pointing to nodes with lower pos). So, the adjacency list for x in the original graph includes nodes with higher and lower pos. But outgoing[x] contains only those with lower pos. The others (higher pos) would be in their outgoing lists, pointing to x. So sum_in[x] is the sum of a[u] for nodes u where u has x in their outgoing list (u's pos is higher than x's pos). And sum_out is the sum of a[u] for nodes u where x points to them (their pos is lower than x's pos). Thus, the total sum for the query is sum_in[x] + sum_out, which is the sum of all adjacent nodes' a's.

Therefore, the code is correct.

Now, the problem is to make this code more efficient. Let's look for possible optimizations.

First, in the compute_degeneracy_order function. The current code uses unordered_set for buckets. However, unordered_set has a high constant factor. For each node processed, it iterates over all its neighbors and updates their degrees and buckets. Since the graph is 10-degenerate, the average degree is low. But for the maximum possible n and m, this could be a problem.

An alternative approach to compute the degeneracy order is to use a priority queue, but that's O(m log n) time, which may be worse. The current approach is using a bucket approach, which is O(n + m), which is better. So the current method is correct, but perhaps the implementation can be optimized.

Wait, the code uses a vector of unordered_sets for buckets. For each u processed, it reduces the degrees of its neighbors and moves them to the appropriate bucket. The problem is that for each neighbor v of u, the code checks if v is in buckets[degree[v]], then removes it, decrements the degree, and inserts into the new bucket. Using unordered_set's count and erase operations may be slow for large n.

An alternative is to represent each bucket as a doubly linked list. Each node has a prev and next pointer. Then, when we need to move a node from one bucket to another, it's O(1) time. But implementing this in C++ would require manual management, which is error-prone but possible.

But perhaps in practice, the current code is acceptable. Let's see: for each node u, when it's processed, it's removed from the current bucket, and all its neighbors' degrees are decreased. Each neighbor v's degree is checked, and if it's in the old bucket, it's removed, and added to the new bucket. For a 10-degenerate graph, each node is processed once, and each edge is processed once. So the total operations are O(m), which for m up to 3e6 is manageable. However, unordered_set's operations have high overhead.

An alternative is to use a vector for each bucket, and track the position of each node in the bucket. But this would complicate things.

Alternatively, since the maximum degree is initially up to n-1, but in practice, for a 10-degenerate graph, the degrees during processing are low. But in any case, the current code may not be the fastest possible.

But for the problem, since the code is supposed to handle up to 3e5 nodes and 3e6 edges, the degeneracy ordering code may take some time. However, given that it's a preprocessing step and not part of the per-query time, it's acceptable as long as it's O(m).

Another possible optimization: when building the outgoing edges, instead of using a vector of vectors, we can use a single contiguous array for all outgoing edges, with indices stored for each node. This can improve cache locality. For example:

vector<int> outgoing_edges;
vector<int> outgoing_start(n+1, 0);

Then, for each node u, outgoing_start[u] to outgoing_start[u+1]-1 gives the indices in outgoing_edges for u's outgoing edges. However, in practice, using vector<vector<int>> is manageable, but for very large n, contiguous storage can help.

But for n up to 3e5 and each outgoing list size up to 10, the total storage is 3e6, which is manageable. So the current approach is acceptable.

Now, looking at the main loop handling queries. For each query of type 1, when we add v to a[x], we iterate over outgoing[x] and add v to sum_in[v] for each v in outgoing[x]. Since outgoing[x] has at most 10 elements, this is O(1) per query.

For queries of type 2, we compute sum_in[x] + sum of a[u] for u in outgoing[x]. Again, O(1) since outgoing[x] has at most 10 elements.

Thus, the code is O(q) time, which is acceptable for q up to 2e6.

Possible optimizations:

1. Using fast I/O: The code already uses ios::sync_with_stdio(false) and cin.tie(nullptr), which is correct.

2. Precomputing the outgoing lists more efficiently.

3. Using arrays instead of vectors for a, sum_in, and outgoing.

In C++, vectors have a slight overhead compared to arrays. So perhaps replacing vectors with dynamically allocated arrays could save some time. For example:

int *a = new int[n];
vector<vector<int>> outgoing(n);

But in practice, vector accesses are as fast as pointers. However, using a plain array for a and sum_in could save some time. For example:

vector<long long> a(n);
vector<long long> sum_in(n, 0);

But the code uses vector, which is fine.

Another optimization: since the outgoing lists are small (up to 10), instead of using a vector<int> for each node, use a fixed-size array. But C++ doesn't support variable-length arrays per node. Alternatively, use a struct with a small array. But in practice, a vector is flexible and manageable.

Another point: in the initial computation of sum_in, for each u, for each v in outgoing[u], sum_in[v] += a[u]. This is O(m) time, but since outgoing has m edges (directed), this is O(m) operations. Since m is up to 3e6, this is acceptable.

Possible issues:

- The compute_degeneracy_order function is taking O(n + m) time, which for 3e6 edges is acceptable.

Another possible optimization: since the graph is undirected, but after orientation, each edge is represented once. So for the outgoing lists, each edge is stored once. For example, if u points to v, then outgoing[u] contains v, but v's outgoing may or may not contain u. But since the original graph is undirected, each edge is processed once in the orientation.

Now, let's think about the sample input. The code should correctly process it. But given that the code passes the sample, perhaps the logic is correct.

But the user says "regenerate more efficient code". So what can be optimized?

One possible area is the compute_degeneracy_order function. Let's try to reimplement it more efficiently.

Current approach uses unordered_sets for buckets, which may be slow. An alternative is to use a list structure with O(1) removal. For example, using a linked list for each bucket. But implementing this in C++ would require a lot of code, but perhaps using a vector and a "present" array.

Alternative approach inspired by the linear time degeneracy ordering (core decomposition) algorithm:

The algorithm to find the degeneracy order (also known as the k-core decomposition) can be implemented efficiently using a bin-sort approach. Here's how:

1. Compute the initial degrees of all nodes.

2. Create an array of nodes sorted by their degrees.

3. For each node in order of increasing degree, remove the node and update the degrees of its neighbors.

But to do this efficiently, we can use a bin structure where for each possible degree, we have a list of nodes with that degree. Then, as we process nodes, we update their neighbors' degrees and move them to the appropriate bins.

This is similar to the current code, but perhaps using a different data structure for the bins. For example, instead of using unordered_set, use a vector for each bin, and track the position of each node in their bin's vector. This allows O(1) removal.

Here's how to do it:

- For each node, maintain its current degree and a pointer (index) to its position in the bin's vector.

- When the degree of a node changes, we can move it from its current bin to the new bin by swapping it with the last element in the current bin's vector and updating the pointer. This allows O(1) removal from the current bin and O(1) addition to the new bin.

This approach is often used in maximum cardinality search algorithms and is more efficient for large datasets.

Implementing this would require:

- An array deg[] storing the current degree of each node.

- An array of vectors bin[], where bin[d] contains nodes with degree d.

- An array pos[] where pos[u] is the index of u in bin[deg[u]].

The algorithm steps would be:

Initialize deg[u] for each node u.

For each u, add u to bin[deg[u]], and set pos[u] to the index in the bin.

current_degree = 0.

order = empty list.

While order.size() < n:

    while current_degree < bin.size() and bin[current_degree].empty():

        current_degree +=1

    if current_degree >= bin.size():

        break

    u = bin[current_degree].back()

    bin[current_degree].pop_back()

    order.append(u)

    for each neighbor v of u:

        if v is not yet processed:

            old_deg = deg[v]

            if old_deg > current_degree:

                // remove v from bin[old_deg]

                index = pos[v]

                swap bin[old_deg][index] with bin[old_deg].back()

                pos[bin[old_deg][index]] = index

                bin[old_deg].pop_back()

                // decrease degree

                deg[v] -=1

                new_deg = deg[v]

                // add to bin[new_deg]

                bin[new_deg].push_back(v)

                pos[v] = bin[new_deg].size() -1

This way, each node is processed once, and each edge is processed once, leading to O(n + m) time.

This approach uses vectors for bins and maintains pos arrays for quick access. This is likely more efficient than using unordered_sets.

So, replacing the current compute_degeneracy_order function with this approach could speed up the preprocessing step.

Thus, the plan is to reimplement the compute_degeneracy_order function using the bin structure with vectors and pos arrays.

This would make the degeneracy ordering faster.

Another optimization is to use adjacency lists stored as arrays of vectors, but in the original code, this is already done.

Now, let's proceed to rewrite the code with this more efficient degeneracy ordering.

Other optimizations:

- Replace the unordered_set in the buckets with the bin structure as described.

- Precompute the outgoing edges more efficiently.

Now, let's draft the code.

The new compute_degeneracy_order function:

vector<int> compute_degeneracy_order(int n, const vector<vector<int>>& adj) {

    vector<int> deg(n);
    for (int u = 0; u < n; ++u) {
        deg[u] = adj[u].size();
    }

    int max_deg = *max_element(deg.begin(), deg.end());
    vector<vector<int>> bin(max_deg + 1);
    vector<int> pos(n);

    for (int u = 0; u < n; ++u) {
        int d = deg[u];
        bin[d].push_back(u);
        pos[u] = bin[d].size() - 1;
    }

    vector<int> order;
    order.reserve(n);

    int current_deg = 0;

    for (int i = 0; i < n; ++i) {
        while (current_deg <= max_deg && bin[current_deg].empty()) {
            current_deg++;
        }
        if (current_deg > max_deg) break;

        int u = bin[current_deg].back();
        bin[current_deg].pop_back();
        order.push_back(u);

        for (int v : adj[u]) {
            if (deg[v] > deg[u]) { // v is still in the graph
                int old_deg = deg[v];
                if (old_deg > current_deg) {
                    // remove v from bin[old_deg]
                    int p = pos[v];
                    if (p < bin[old_deg].size()) {
                        int w = bin[old_deg].back();
                        bin[old_deg][p] = w;
                        pos[w] = p;
                        bin[old_deg].pop_back();
                        // decrease degree
                        deg[v]--;
                        int new_deg = deg[v];
                        if (new_deg >= bin.size()) {
                            bin.resize(new_deg + 1);
                            max_deg = new_deg;
                        }
                        bin[new_deg].push_back(v);
                        pos[v] = bin[new_deg].size() - 1;
                    }
                }
            }
        }
        deg[u] = -1; // mark as processed
    }

    return order;
}

Wait, but in this code, after processing u, we need to mark it as processed. Also, when iterating over the neighbors v of u, we need to check if v is still in the graph (i.e., not yet processed). But how? Because once a node is processed (added to order), its deg is set to -1. So, when processing u, for each neighbor v, if deg[v] > deg[u], which is possible if v hasn't been processed yet. Wait, but when u is processed, its degree is current_deg. Nodes v with deg[v] <= current_deg have already been processed?

No, this logic is incorrect. Because the current_deg may have been increased, but the nodes in lower degrees may not have been processed.

Wait, the degeneracy order is computed by selecting the node with the smallest current degree each time. So, when u is processed, its degree is current_deg, which is the smallest possible. Any node v that is a neighbor of u and has not been processed yet may have a degree higher than or equal to current_deg.

But when we process u, we need to decrease the degrees of its neighbors v that are still unprocessed. So, for each v in adj[u], if deg[v] is not -1 (i.e., not processed), then we need to update their degrees.

So, the code should check if v is unprocessed (deg[v] != -1). Then, for such v, decrease their degree.

So, the revised code would be:

vector<int> compute_degeneracy_order(int n, const vector<vector<int>>& adj) {

    vector<int> deg(n);
    for (int u = 0; u < n; ++u) {
        deg[u] = adj[u].size();
    }

    int max_deg = *max_element(deg.begin(), deg.end());
    vector<vector<int>> bin(max_deg + 1);
    vector<int> pos(n);

    for (int u = 0; u < n; ++u) {
        int d = deg[u];
        if (d >= bin.size()) {
            bin.resize(d + 1);
            max_deg = max(max_deg, d);
        }
        bin[d].push_back(u);
        pos[u] = bin[d].size() - 1;
    }

    vector<int> order;
    order.reserve(n);

    int current_deg = 0;

    for (int i = 0; i < n; ++i) {
        while (current_deg <= max_deg && bin[current_deg].empty()) {
            current_deg++;
        }
        if (current_deg > max_deg) break;

        int u = bin[current_deg].back();
        bin[current_deg].pop_back();
        order.push_back(u);
        deg[u] = -1; // mark as processed

        for (int v : adj[u]) {
            if (deg[v] != -1) { // v is not processed yet
                int old_deg = deg[v];
                if (old_deg > current_deg) {
                    // remove v from bin[old_deg]
                    if (old_deg >= bin.size()) {
                        continue; // should not happen
                    }
                    vector<int>& b = bin[old_deg];
                    int p = pos[v];
                    if (p >= b.size()) continue; // already removed?
                    if (b[p] != v) continue; // this can happen if v was moved
                    // swap with last element
                    if (!b.empty()) {
                        int last = b.back();
                        b[p] = last;
                        pos[last] = p;
                        b.pop_back();
                        pos[v] = -1; // invalidate
                    }
                    // decrease degree
                    deg[v]--;
                    int new_deg = deg[v];
                    if (new_deg < 0) new_deg = 0;
                    if (new_deg >= bin.size()) {
                        bin.resize(new_deg + 1);
                        max_deg = new_deg;
                    }
                    bin[new_deg].push_back(v);
                    pos[v] = bin[new_deg].size() - 1;
                }
            }
        }
    }

    return order;
}

But this code has some edge cases. For example, when a node v is in bin[old_deg], but during processing, its position p may not correspond to v if the bin has been modified. So the code checks if b[p] == v. If not, skip. This can happen if v was previously moved due to another node's processing.

This is a possible optimization, but it's complicated. However, this approach should be faster than using unordered_sets.

Another point: when processing a neighbor v of u, if the old_deg of v is greater than current_deg, we need to decrease its degree and move it to the new bin.

But in this case, if v's old_deg is not greater than current_deg, then v's degree is already <= current_deg, so it will be processed later, but since current_deg can increase, perhaps this case is already handled.

But the main idea is that when processing u with current_deg, any neighbor v with degree higher than current_deg will have their degree reduced, possibly allowing them to be processed earlier.

This should correctly compute the degeneracy order.

By using this bin approach with vectors and pos arrays, the compute_degeneracy_order function should be more efficient than the previous version with unordered_sets.

Another optimization: in the main code, after the order is computed, the outgoing edges are built by comparing positions. Since the pos array is the reverse of the order (order[i] is the node at position i), pos[u] is the index in the order. So for two nodes u and v, if pos[u] > pos[v], then u comes later in the order, so we add v to outgoing[u].

Thus, the outgoing edges can be built by iterating through all edges and adding them in the direction from u to v if pos[u] > pos[v].

But for the adjacency list, each edge is stored twice (since the graph is undirected). So for each edge (u, v), we process both directions.

But when building outgoing edges, for each u in 0..n-1:

    for each v in adj[u]:

        if pos[u] > pos[v]:

            outgoing[u].push_back(v);

This way, each edge is considered in both directions, but only one direction is added to the outgoing list.

This is O(m) time, which is acceptable.

Now, implementing this new compute_degeneracy_order function should speed up the preprocessing.

Other possible optimizations:

- Use integers instead of vectors for the bins. But in C++, vectors are efficient.

- Pre-allocate the bin vectors to avoid resizing. But since the maximum degree is initially computed, this is done in the code.

Now, let's check the sample input to ensure the new code works.

But without running the code, it's hard to say. However, given the logical steps, this approach should work.

Another optimization: when building the outgoing edges, pre-reserve space. For example, for each node u, outgoing[u].reserve(10), since the graph is 10-degenerate.

But in practice, this may not be necessary, but it can reduce reallocations.

Thus, after computing the order and pos array, for each u, reserve adj[u].size() for outgoing[u], but since outgoing[u] will contain only a subset of adj[u] (those with lower pos), maybe reserving 10 is better.

But how to know the maximum out-degree? Since the graph is 10-degenerate, the maximum out-degree is 10. So, for each u, outgoing[u].reserve(10).

But this requires a loop:

for (int u = 0; u < n; ++u) {

    outgoing[u].reserve(10);

}

But for 3e5 nodes, this loop is O(n), which is acceptable.

This can help reduce dynamic allocations during the building of outgoing edges.

Another optimization: using a single vector to store all outgoing edges, with indices for each node's start and end. This can improve cache locality, but may complicate the code. For example:

vector<int> outgoing_edges;
vector<int> outgoing_start(n+1, 0);

But this requires precomputing the number of outgoing edges for each node first. For example:

vector<int> out_degree(n, 0);

for (int u = 0; u < n; ++u) {

    for (int v : adj[u]) {

        if (pos[u] > pos[v]) {

            out_degree[u]++;

        }

    }

}

Then, compute the prefix sum for outgoing_start:

outgoing_start[0] = 0;

for (int u = 0; u < n; ++u) {

    outgoing_start[u+1] = outgoing_start[u] + out_degree[u];

}

outgoing_edges.resize(outgoing_start[n]);

Then, fill the outgoing_edges:

vector<int> current(n, 0);

for (int u = 0; u < n; ++u) {

    for (int v : adj[u]) {

        if (pos[u] > pos[v]) {

            int idx = outgoing_start[u] + current[u]++;

            outgoing_edges[idx] = v;

        }

    }

}

But this approach may be more efficient for iterating through outgoing edges during queries, as the data is contiguous. However, during queries, each outgoing list is small (up to 10), so the overhead of a vector is minimal. But for cache efficiency, this approach may help.

But this requires more code and additional steps. For the sake of time and code simplicity, the original code may be better, but for maximum efficiency, this could be considered.

However, given time constraints, perhaps the original code's approach is sufficient, and the main optimization is in the compute_degeneracy_order function.

Another point: in the original code, after processing the order, we compute pos as the index in the order. For example, order is a vector of nodes in the order they were processed. pos[u] is the index of u in the order. So for u in order[i], pos[u] = i.

But the way pos is computed in the original code is:

for (int i = 0; i < n; ++i) {

    pos[order[i]] = i;

}

This is correct.

Now, putting it all together.

Thus, the revised code would use the new compute_degeneracy_order function with the bin structure and pos arrays.

This should lead to a more efficient preprocessing step.

Other minor optimizations:

- Use scanf and printf instead of cin and cout. Although the code uses ios_base::sync_with_stdio(false), in practice, scanf and printf are faster for large input. But in the original code, cin is used, and converting to scanf would require changes.

But the problem's input is large, and using scanf may speed up reading.

Thus, the code can be modified to use scanf for input.

But the original code uses:

cin >> n >> m >> q;

Then reads m edges with cin.

Then reads n a_i with cin.

Then reads q queries with cin.

Using scanf for these inputs can be faster.

Thus, changing the code to use scanf for input and printf for output can improve performance.

In the original code, the query handling uses cin for each line. For each query, the code reads the type, then x and possibly v.

Reading with scanf can be faster.

For example, in the main loop:

while (q--) {

    int type;

    scanf("%d", &type);

    if (type == 1) {

        int x, v;

        scanf("%d%d", &x, &v);

        x--;

        a[x] += v;

        for (int u : outgoing[x]) {

            sum_in[u] += v;

        }

    } else {

        int x;

        scanf("%d", &x);

        x--;

        long long sum_out = 0;

        for (int u : outgoing[x]) {

            sum_out += a[u];

        }

        printf("%lld\n", sum_in[x] + sum_out);

    }

}

This can be faster than using cin.

Thus, modifying the code to use scanf and printf would help.

Another optimization: precompute the outgoing edges as lists of integers, and during the sum_in initialization, use those lists.

Thus, the revised code would:

- Use the new compute_degeneracy_order function.

- Use scanf/printf for I/O.

- Pre-reserve space for outgoing edges.

So, the final code would look like:

#include <bits/stdc++.h>
using namespace std;

vector<int> compute_degeneracy_order(int n, const vector<vector<int>>& adj) {
    vector<int> deg(n);
    for (int u = 0; u < n; ++u) {
        deg[u] = adj[u].size();
    }

    int max_deg = *max_element(deg.begin(), deg.end());
    vector<vector<int>> bin(max_deg + 1);
    vector<int> pos(n);

    for (int u = 0; u < n; ++u) {
        int d = deg[u];
        if (d >= bin.size()) {
            bin.resize(d + 1);
        }
        bin[d].push_back(u);
        pos[u] = bin[d].size() - 1;
    }

    vector<int> order;
    order.reserve(n);

    int current_deg = 0;

    for (int i = 0; i < n; ++i) {
        while (current_deg <= max_deg && bin[current_deg].empty()) {
            current_deg++;
        }
        if (current_deg > max_deg) break;

        int u = bin[current_deg].back();
        bin[current_deg].pop_back();
        order.push_back(u);
        deg[u] = -1;

        for (int v : adj[u]) {
            if (deg[v] != -1) { // v is not processed
                int old_deg = deg[v];
                if (old_deg > current_deg) {
                    if (old_deg >= bin.size()) continue;
                    vector<int>& b = bin[old_deg];
                    int p = pos[v];
                    if (p >= b.size() || b[p] != v) continue;

                    if (!b.empty()) {
                        int last = b.back();
                        b[p] = last;
                        pos[last] = p;
                        b.pop_back();
                    }

                    deg[v]--;
                    int new_deg = deg[v];
                    if (new_deg < 0) new_deg = 0;
                    if (new_deg >= bin.size()) {
                        bin.resize(new_deg + 1);
                        max_deg = max(max_deg, new_deg);
                    }
                    bin[new_deg].push_back(v);
                    pos[v] = bin[new_deg].size() - 1;
                }
            }
        }
    }

    return order;
}

int main() {
    int n, m, q;
    scanf("%d %d %d", &n, &m, &q);

    vector<vector<int>> adj(n);
    for (int i = 0; i < m; ++i) {
        int u, v;
        scanf("%d %d", &u, &v);
        u--; v--;
        adj[u].push_back(v);
        adj[v].push_back(u);
    }

    vector<int> order = compute_degeneracy_order(n, adj);
    vector<int> pos(n);
    for (int i = 0; i < n; ++i) {
        pos[order[i]] = i;
    }

    vector<vector<int>> outgoing(n);
    for (int u = 0; u < n; ++u) {
        for (int v : adj[u]) {
            if (pos[u] > pos[v]) {
                outgoing[u].push_back(v);
            }
        }
        outgoing[u].shrink_to_fit();
    }

    vector<long long> a(n);
    for (int i = 0; i < n; ++i) {
        scanf("%lld", &a[i]);
    }

    vector<long long> sum_in(n, 0);
    for (int u = 0; u < n; ++u) {
        for (int v : outgoing[u]) {
            sum_in[v] += a[u];
        }
    }

    while (q--) {
        int type;
        scanf("%d", &type);
        if (type == 1) {
            int x, v;
            scanf("%d %d", &x, &v);
            x--;
            a[x] += v;
            for (int u : outgoing[x]) {
                sum_in[u] += v;
            }
        } else {
            int x;
            scanf("%d", &x);
            x--;
            long long sum_out = 0;
            for (int u : outgoing[x]) {
                sum_out += a[u];
            }
            printf("%lld\n", sum_in[x] + sum_out);
        }
    }

    return 0;
}

Changes made:

1. Replaced compute_degeneracy_order with the bin approach using vectors and pos arrays for O(1) operations.

2. Changed I/O to use scanf and printf for faster input/output.

3. Added shrink_to_fit to the outgoing vectors to reduce memory usage, though this is optional.

4. Used %lld format specifier for long long in printf.

These changes should improve the efficiency of the code, especially for large inputs.